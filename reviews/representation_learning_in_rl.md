
# Literature Review 
# Representation Learning in Reinforcement Learning

## NIPS

### 2022ðŸ”–

[ ðŸ”– ] DOMINO: Decomposed Mutual Information Optimization for Generalized Context in Meta-Reinforcement Learning

[ ðŸ”– ] Does Self-supervised Learning Really Improve Reinforcement Learning from Pixels?

[ ðŸ”– ] Explaining a Reinforcement Learning Agent via Prototyping

[ ðŸ”– ]  Pre-Trained Image Encoder for Generalizable Visual Reinforcement Learning

[ ðŸ”– ] A Mixture Of Surprises for Unsupervised Reinforcement Learning

[ ðŸ”– ] Spectrum Random Masking for Generalization in Image-based Reinforcement Learning

[ ðŸ”– ] S2P: State-conditioned Image Synthesis for Data Augmentation in Offline Reinforcement Learning

[ ðŸ”– ] Learning Representations via a Robust Behavioral Metric for Deep Reinforcement Learning

[ ðŸ”– ] On the Effect of Pre-training for Transformer in Different Modality on Offline Reinforcement Learning

[ ðŸ”– ] Provable Benefit of Multitask Representation Learning in Reinforcement Learning

[ ðŸ”– ] Explainable Reinforcement Learning via Model Transforms

[ ðŸ”– ] Discrete Compositional Representations as an Abstraction for Goal Conditioned Reinforcement Learning

[ ðŸ”– ] Robust Reinforcement Learning using Offline Data

[ ðŸ”– ] Unsupervised Reinforcement Learning with Contrastive Intrinsic Control

### 2021

[ ðŸ”– ] Widening the Pipeline in Human-Guided Reinforcement Learning with Explanation and Context-Aware Data Augmentation

[ ðŸ”– ] Design of Experiments for Stochastic Contextual Linear Bandits

[ ðŸ”– ] Off-Policy Risk Assessment in Contextual Bandits

[ ðŸ”– ] Federated Linear Contextual Bandits

[ ðŸ”– ] Environment Generation for Zero-Shot Compositional Reinforcement Learning

[ ðŸ”– ] Learning Markov State Abstractions for Deep Reinforcement Learning

[ ðŸ”– ] Towards Deeper Deep Reinforcement Learning with Spectral Normalization

[ ðŸ”– ] Learning MDPs from Features: Predict-Then-Optimize for Sequential Decision Making by Reinforcement Learning

[ ðŸ”– ] Pretraining Representations for Data-Efficient Reinforcement Learning

[ ðŸ”– ] Agnostic Reinforcement Learning with Low-Rank MDPs and Rich Observations

[ ðŸ”– ] Functional Regularization for Reinforcement Learning via Learned Fourier Features

[ ðŸ”– ] Agent Modelling under Partial Observability for Deep Reinforcement Learning

[ ðŸ”– ] Improving Computational Efficiency in Visual Reinforcement Learning via Stored Embeddings

[ ðŸ”– ] Successor Feature Landmarks for Long-Horizon Goal-Conditioned Reinforcement Learning

[ ðŸ”– ] Unsupervised Domain Adaptation with Dynamics-Aware Rewards in Reinforcement Learning


### 2020

[ ðŸ”– ] Reinforcement Learning with Augmented Data

[ ðŸ”– ] Is Plug-in Solver Sample-Efficient for Feature-based Reinforcement Learning?

[ ðŸ”– ] Robust Reinforcement Learning via Adversarial training with Langevin Dynamics

[ ðŸ”– ] Robust Deep Reinforcement Learning against Adversarial Perturbations on State Observations


## ICLR

### 2022

### 2021

### 2020


## ICML

### 2022

### 2021

### 2020

## AAAI

### 2022

[ ðŸ”– ] Fast and Data Efficient Reinforcement Learning from Pixels via Non-Parametric Value Approximation

[ ðŸ”– ] Same State, Different Task: Continual Reinforcement Learning without Interference

[ ðŸ”– ] Enforcement Heuristics for Argumentation with Deep Reinforcement Learning

[ ðŸ”– ] CADRE: A Cascade Deep Reinforcement Learning Framework for Vision-Based Autonomous Urban Driving

[ ðŸ”– ] Structure Learning-Based Task Decomposition for Reinforcement Learning In Non-Stationary Environments

[ ðŸ”– ] Generalizing Reinforcement Learning through Fusing Self-Supervised Learning into Intrinsic Motivation

[ ðŸ”– ] Unsupervised Reinforcement Learning in Multiple Environments

[ ðŸ”– ] Introducing Symmetries to Black Box Meta Reinforcement Learning

[ ðŸ”– ] Wasserstein Unsupervised Reinforcement Learning

[ ðŸ”– ] Learning by Competition of Self-Interested Reinforcement Learning Agents

[ ðŸ”– ] SimSR: Simple Distance-Based State Representations for Deep Reinforcement Learning

[ ðŸ”– ] Blockwise Sequential Model Learning for Partially Observable Reinforcement Learning

[ ðŸ”– ] Deep Reinforcement Learning Policies Learn Shared Adversarial Features Across MDPs


### 2021

[ ðŸ”– ] Self-Supervised Attention-Aware Reinforcement Learning 

[ ðŸ”– ] Sequential Generative Exploration Model for Partially Observable Reinforcement Learning

[ ðŸ”– ] Towards Effective Context for Meta-Reinforcement Learning: An Approach Based on Contrastive Learning

[ ðŸ”– ] Improving Sample Efficiency in Model-Free Reinforcement Learning from Images

[ ðŸ”– ] Domain Adaptation in Reinforcement Learning via Latent Unified State Representation

[ ðŸ”– ] Reinforcement Learning with a Disentangled Universal Value Function for Item Recommendation

[ ðŸ”– ] The Value-Improvement Path: Towards Better Representations for Reinforcement Learning

[ ðŸ”– ] Uncertainty-Aware Multi-View Representation Learning

[ ðŸ”– ] Distilling Localization for Self-Supervised Representation Learning

[ ðŸ”– ] MERL: Multimodal Event Representation Learning in Heterogeneous Embedding Spaces



## IJCAI

### 2022


[ ðŸ”– ] Feature and Instance Joint Selection: A Reinforcement Learning Perspective

[ ðŸ”– ] Self-Predictive Dynamics for Generalization of Vision-based Reinforcement Learning

[ ðŸ”– ] Donâ€™t Touch What Matters: Task-Aware Lipschitz Data Augmentation for Visual Reinforcement Learning

### 2021

[ ðŸ”– ] Deep Reinforcement Learning Boosted Partial Domain Adaptation


### 2020

[ ðŸ”– ] Efficient Deep Reinforcement Learning via Adaptive Policy Transfer

[ ðŸ”– ] I4R: Promoting Deep Reinforcement Learning by the Indicator for Expressive Representations

[ ðŸ”– ] KoGuN: Accelerating Deep Reinforcement Learning via Integrating Human Suboptimal Knowledge

