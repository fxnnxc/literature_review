
# Literature Review : Representation Learning in Reinforcement Learning

## NIPS

### 2022

[ðŸ“œ] DOMINO: Decomposed Mutual Information Optimization for Generalized Context in Meta-Reinforcement Learning

[ðŸ“œ] Does Self-supervised Learning Really Improve Reinforcement Learning from Pixels?

[ðŸ“œ] Explaining a Reinforcement Learning Agent via Prototyping

[ðŸ“œ]  Pre-Trained Image Encoder for Generalizable Visual Reinforcement Learning

[ðŸ“œ] A Mixture Of Surprises for Unsupervised Reinforcement Learning

[ðŸ“œ] Spectrum Random Masking for Generalization in Image-based Reinforcement Learning

[ðŸ“œ] S2P: State-conditioned Image Synthesis for Data Augmentation in Offline Reinforcement Learning

[ðŸ“œ] Learning Representations via a Robust Behavioral Metric for Deep Reinforcement Learning

[ðŸ“œ] On the Effect of Pre-training for Transformer in Different Modality on Offline Reinforcement Learning

[ðŸ“œ] Provable Benefit of Multitask Representation Learning in Reinforcement Learning

[ðŸ“œ] Explainable Reinforcement Learning via Model Transforms

[ðŸ“œ] Discrete Compositional Representations as an Abstraction for Goal Conditioned Reinforcement Learning

[ðŸ“œ] Robust Reinforcement Learning using Offline Data

[ðŸ“œ] Unsupervised Reinforcement Learning with Contrastive Intrinsic Control

### 2021

[ðŸ“œ] Widening the Pipeline in Human-Guided Reinforcement Learning with Explanation and Context-Aware Data Augmentation

[ðŸ“œ] Design of Experiments for Stochastic Contextual Linear Bandits

[ðŸ“œ] Off-Policy Risk Assessment in Contextual Bandits

[ðŸ“œ] Federated Linear Contextual Bandits

[ðŸ“œ] Environment Generation for Zero-Shot Compositional Reinforcement Learning

[ðŸ“œ] Learning Markov State Abstractions for Deep Reinforcement Learning

[ðŸ“œ] Towards Deeper Deep Reinforcement Learning with Spectral Normalization

[ðŸ“œ] Learning MDPs from Features: Predict-Then-Optimize for Sequential Decision Making by Reinforcement Learning

[ðŸ“œ] Pretraining Representations for Data-Efficient Reinforcement Learning

[ðŸ“œ] Agnostic Reinforcement Learning with Low-Rank MDPs and Rich Observations

[ðŸ“œ] Functional Regularization for Reinforcement Learning via Learned Fourier Features

[ðŸ“œ] Agent Modelling under Partial Observability for Deep Reinforcement Learning

[ðŸ“œ] Improving Computational Efficiency in Visual Reinforcement Learning via Stored Embeddings

[ðŸ“œ] Successor Feature Landmarks for Long-Horizon Goal-Conditioned Reinforcement Learning

[ðŸ“œ] Unsupervised Domain Adaptation with Dynamics-Aware Rewards in Reinforcement Learning


### 2020

[ðŸ“œ] Reinforcement Learning with Augmented Data

[ðŸ“œ] Is Plug-in Solver Sample-Efficient for Feature-based Reinforcement Learning?

[ðŸ“œ] Robust Reinforcement Learning via Adversarial training with Langevin Dynamics

[ðŸ“œ] Robust Deep Reinforcement Learning against Adversarial Perturbations on State Observations


## ICLR

### 2022

### 2021

### 2020


## ICML

### 2022

### 2021

### 2020

## AAAI

### 2022

[ðŸ“œ] Fast and Data Efficient Reinforcement Learning from Pixels via Non-Parametric Value Approximation

[ðŸ“œ] Same State, Different Task: Continual Reinforcement Learning without Interference

[ðŸ“œ] Enforcement Heuristics for Argumentation with Deep Reinforcement Learning

[ðŸ“œ] CADRE: A Cascade Deep Reinforcement Learning Framework for Vision-Based Autonomous Urban Driving

[ðŸ“œ] Structure Learning-Based Task Decomposition for Reinforcement Learning In Non-Stationary Environments

[ðŸ“œ] Generalizing Reinforcement Learning through Fusing Self-Supervised Learning into Intrinsic Motivation

[ðŸ“œ] Unsupervised Reinforcement Learning in Multiple Environments

[ðŸ“œ] Introducing Symmetries to Black Box Meta Reinforcement Learning

[ðŸ“œ] Wasserstein Unsupervised Reinforcement Learning

[ðŸ“œ] Learning by Competition of Self-Interested Reinforcement Learning Agents

[ðŸ“œ] SimSR: Simple Distance-Based State Representations for Deep Reinforcement Learning

[ðŸ“œ] Blockwise Sequential Model Learning for Partially Observable Reinforcement Learning

[ðŸ“œ] Deep Reinforcement Learning Policies Learn Shared Adversarial Features Across MDPs


### 2021

[ðŸ“œ] Self-Supervised Attention-Aware Reinforcement Learning 
[ðŸ“œ] Sequential Generative Exploration Model for Partially Observable Reinforcement Learning
[ðŸ“œ] Towards Effective Context for Meta-Reinforcement Learning: An Approach Based on Contrastive Learning
[ðŸ“œ] Improving Sample Efficiency in Model-Free Reinforcement Learning from Images
[ðŸ“œ] Domain Adaptation in Reinforcement Learning via Latent Unified State Representation
[ðŸ“œ] Reinforcement Learning with a Disentangled Universal Value Function for Item Recommendation
[ðŸ“œ] The Value-Improvement Path: Towards Better Representations for Reinforcement Learning
[ðŸ“œ] Uncertainty-Aware Multi-View Representation Learning
[ðŸ“œ] Distilling Localization for Self-Supervised Representation Learning
[ðŸ“œ] MERL: Multimodal Event Representation Learning in Heterogeneous Embedding Spaces



## IJCAI

### 2022


[ðŸ“œ] Feature and Instance Joint Selection: A Reinforcement Learning Perspective

[ðŸ“œ] Self-Predictive Dynamics for Generalization of Vision-based Reinforcement Learning

[ðŸ“œ] Donâ€™t Touch What Matters: Task-Aware Lipschitz Data Augmentation for Visual Reinforcement Learning

### 2021

[ðŸ“œ] Deep Reinforcement Learning Boosted Partial Domain Adaptation


### 2020

[ðŸ“œ] Efficient Deep Reinforcement Learning via Adaptive Policy Transfer

[ðŸ“œ] I4R: Promoting Deep Reinforcement Learning by the Indicator for Expressive Representations

[ðŸ“œ] KoGuN: Accelerating Deep Reinforcement Learning via Integrating Human Suboptimal Knowledge

